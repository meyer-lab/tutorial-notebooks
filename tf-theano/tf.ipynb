{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(101)\n",
    "tf.set_random_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random linear data \n",
    "# There will be 50 data points ranging from 0 to 50\n",
    "x = np.linspace(0, 50, 50) + np.random.uniform(-4, 4, 50)\n",
    "y = np.linspace(0, 50, 50) + np.random.uniform(-4, 4, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of Training Data \n",
    "plt.scatter(x, y) \n",
    "plt.xlabel('x')\n",
    "plt.xlabel('y')\n",
    "plt.title(\"Training Data\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "W = tf.Variable(np.random.randn(), name = \"W\")\n",
    "b = tf.Variable(np.random.randn(), name = \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis \n",
    "y_pred = tf.add(tf.multiply(X, W), b)\n",
    "\n",
    "# Mean Squared Error Cost Function\n",
    "cost = tf.norm(y_pred - Y)\n",
    "\n",
    "# Gradient Descent Optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Global Variables Initializer \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the Tensorflow Session \n",
    "with tf.Session() as sess: \n",
    "    \n",
    "    # Initializing the Variables \n",
    "    sess.run(init) \n",
    "    \n",
    "    # Iterating through all the epochs \n",
    "    for epoch in range(10000):\n",
    "        # Feeding each data point into the optimizer using Feed Dictionary \n",
    "        sess.run(optimizer, feed_dict = {X : x, Y : y}) \n",
    "\n",
    "        # Displaying the result after every 40 epochs \n",
    "        if (epoch + 1) % 5000 == 0: \n",
    "            # Calculating the cost a every epoch \n",
    "            c = sess.run(cost, feed_dict = {X : x, Y : y})\n",
    "            c_grad = sess.run(tf.gradients(cost, [W, b], stop_gradients=[W, b]), feed_dict ={X: x, Y: y})\n",
    "            print(\"Gradients:\", c_grad)\n",
    "            print(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b)) \n",
    "\n",
    "    # Storing necessary values to be used outside the Session \n",
    "    training_cost = sess.run(cost, feed_dict ={X: x, Y: y})\n",
    "    weight = sess.run(W) \n",
    "    bias = sess.run(b) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
